{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Complete Google Colab Guide: Electricity Price Forecasting\n",
        "\n",
        "## **WORKING SOLUTION CONFIRMED!**\n",
        "\n",
        "This comprehensive notebook provides a complete electricity price forecasting solution optimized for Google Colab. It includes:\n",
        "- Real ENTSO-E API data download\n",
        "- Multiple ML and time series models\n",
        "- Interactive visualizations with Plotly\n",
        "- Business impact analysis\n",
        "- Robust error handling and fallbacks\n",
        "\n",
        "## Quick Start\n",
        "1. **Run Setup Cell** - Install packages and clone repository\n",
        "2. **Run Data Collection** - Get real or synthetic data\n",
        "3. **Run Model Training** - Train multiple forecasting models\n",
        "4. **Run Evaluation** - Compare model performance\n",
        "5. **Run Analysis** - Business impact and insights\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Installation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install packages and clone repository\n",
        "%pip install xgboost lightgbm prophet tensorflow torch plotly streamlit beautifulsoup4\n",
        "!git clone https://github.com/tommasomalaguti/energy_price_predictor.git\n",
        "%cd energy_price_predictor\n",
        "\n",
        "print(\"Setup complete!\")\n",
        "print(f\"Current directory: {os.getcwd()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Import Libraries and Setup Environment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Add the src directory to Python path\n",
        "sys.path.append('src')\n",
        "sys.path.append('.')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Check if we can find our modules\n",
        "print(\"Checking module paths...\")\n",
        "print(f\"Current directory: {os.getcwd()}\")\n",
        "print(f\"Files in current directory: {os.listdir('.')}\")\n",
        "\n",
        "if os.path.exists('src'):\n",
        "    print(f\"Files in src directory: {os.listdir('src')}\")\n",
        "    if os.path.exists('src/data'):\n",
        "        print(f\"Files in src/data directory: {os.listdir('src/data')}\")\n",
        "    if os.path.exists('src/models'):\n",
        "        print(f\"Files in src/models directory: {os.listdir('src/models')}\")\n",
        "\n",
        "# Import our modules with proper error handling\n",
        "try:\n",
        "    from src.data.entsoe_downloader import ENTSOEDownloader\n",
        "    from src.data.preprocessor import DataPreprocessor\n",
        "    from src.models.baseline_models import BaselineModels\n",
        "    from src.models.ml_models import MLModels\n",
        "    from src.models.time_series_models import TimeSeriesModels\n",
        "    from src.evaluation.metrics import EvaluationMetrics\n",
        "    from src.evaluation.visualization import ModelVisualization\n",
        "    print(\"All modules imported successfully!\")\n",
        "except ImportError as e:\n",
        "    print(f\"Import error: {e}\")\n",
        "    print(\"Trying alternative import paths...\")\n",
        "    \n",
        "    # Try alternative import paths\n",
        "    try:\n",
        "        from data.entsoe_downloader import ENTSOEDownloader\n",
        "        from data.preprocessor import DataPreprocessor\n",
        "        from models.baseline_models import BaselineModels\n",
        "        from models.ml_models import MLModels\n",
        "        from models.time_series_models import TimeSeriesModels\n",
        "        from evaluation.metrics import EvaluationMetrics\n",
        "        from evaluation.visualization import ModelVisualization\n",
        "        print(\"Modules imported with alternative paths!\")\n",
        "    except ImportError as e2:\n",
        "        print(f\"Alternative import also failed: {e2}\")\n",
        "        print(\"Please check the file structure and try again.\")\n",
        "\n",
        "print(\"\\nEnvironment setup complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Collection - Real ENTSO-E Data\n",
        "\n",
        "This section downloads real electricity price data from the ENTSO-E API. If the API fails, it will automatically fall back to synthetic data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# WORKING SOLUTION: Get real electricity price data from ENTSO-E API\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "ENTSOE_API_TOKEN = \"2c8cd8e0-0a84-4f67-90ba-b79d07ab2667\"\n",
        "\n",
        "print(\"Getting real electricity price data...\")\n",
        "\n",
        "def get_real_data():\n",
        "    \"\"\"Get real electricity price data from ENTSO-E API.\"\"\"\n",
        "    \n",
        "    # Try working countries first, then Italy\n",
        "    countries = {\n",
        "        'France': '10YFR-RTE------C',\n",
        "        'Netherlands': '10YNL----------L', \n",
        "        'Spain': '10YES-REE------0',\n",
        "        'Italy': '10YIT----------'\n",
        "    }\n",
        "    \n",
        "    # Try to get data over extended period for maximum records\n",
        "    print(\"Attempting to collect data over extended period...\")\n",
        "    \n",
        "    for country_name, domain_code in countries.items():\n",
        "        print(f\"\\nTrying {country_name}...\")\n",
        "        \n",
        "        # Try to get data for the last 3 years (optimal for ML training)\n",
        "        all_data = []\n",
        "        today = datetime.now()\n",
        "        \n",
        "        for days_back in range(1, 1096):  # Try last 3 years for optimal ML training\n",
        "            test_date = today - timedelta(days=days_back)\n",
        "            date_str = test_date.strftime('%Y%m%d')\n",
        "            print(f\"  {days_back} days ago ({date_str})... [{days_back}/1095]\")\n",
        "            \n",
        "            # API request parameters\n",
        "            params = {\n",
        "                'documentType': 'A44',\n",
        "                'in_Domain': domain_code,\n",
        "                'out_Domain': domain_code,\n",
        "                'periodStart': f'{date_str}0000',\n",
        "                'periodEnd': f'{date_str}2359',\n",
        "                'securityToken': ENTSOE_API_TOKEN\n",
        "            }\n",
        "            \n",
        "            try:\n",
        "                response = requests.get(\"https://web-api.tp.entsoe.eu/api\", params=params, timeout=30)\n",
        "                print(f\"    Status: {response.status_code}\")\n",
        "                \n",
        "                if response.status_code == 200:\n",
        "                    # Parse XML response\n",
        "                    soup = BeautifulSoup(response.text, 'xml')\n",
        "                    \n",
        "                    # Check if it's an Acknowledgement document (no data)\n",
        "                    if soup.find('Acknowledgement_MarketDocument'):\n",
        "                        print(f\"    No data available\")\n",
        "                        continue\n",
        "                    \n",
        "                    # Look for actual price data\n",
        "                    time_series = soup.find_all('TimeSeries')\n",
        "                    print(f\"    Found {len(time_series)} time series\")\n",
        "                    \n",
        "                    if time_series:\n",
        "                        # Parse the data\n",
        "                        day_data = parse_price_data(soup)\n",
        "                        \n",
        "                        if day_data is not None and len(day_data) > 0:\n",
        "                            print(f\"    Got {len(day_data)} records\")\n",
        "                            all_data.append(day_data)\n",
        "                        else:\n",
        "                            print(f\"    No price data found\")\n",
        "                    else:\n",
        "                        print(f\"    No time series found\")\n",
        "                        \n",
        "            except Exception as e:\n",
        "                print(f\"    Error: {e}\")\n",
        "                continue\n",
        "        \n",
        "        # If we got data from multiple days, combine it\n",
        "        if all_data:\n",
        "            combined_data = pd.concat(all_data, ignore_index=True)\n",
        "            combined_data = combined_data.sort_values('datetime').reset_index(drop=True)\n",
        "            \n",
        "            print(f\"SUCCESS! Combined {len(combined_data)} records from {len(all_data)} days\")\n",
        "            print(f\"Price range: €{combined_data['price'].min():.2f} - €{combined_data['price'].max():.2f}/MWh\")\n",
        "            print(f\"Date range: {combined_data['datetime'].min()} to {combined_data['datetime'].max()}\")\n",
        "            \n",
        "            # Add time features\n",
        "            combined_data['hour'] = combined_data['datetime'].dt.hour\n",
        "            combined_data['day_of_week'] = combined_data['datetime'].dt.dayofweek\n",
        "            combined_data['month'] = combined_data['datetime'].dt.month\n",
        "            combined_data['year'] = combined_data['datetime'].dt.year\n",
        "            \n",
        "            print(f\"Real data from {country_name} ready!\")\n",
        "            return combined_data\n",
        "    \n",
        "    print(\"\\nNo real data found. Using synthetic data...\")\n",
        "    return generate_synthetic_data()\n",
        "\n",
        "def parse_price_data(soup):\n",
        "    \"\"\"Parse price data from XML response.\"\"\"\n",
        "    try:\n",
        "        time_series = soup.find_all('TimeSeries')\n",
        "        data = []\n",
        "        \n",
        "        for ts in time_series:\n",
        "            points = ts.find_all('Point')\n",
        "            \n",
        "            for point in points:\n",
        "                try:\n",
        "                    position = int(point.find('position').text)\n",
        "                    price = float(point.find('price.amount').text)\n",
        "                    \n",
        "                    start_time = ts.find('start').text\n",
        "                    start_dt = datetime.fromisoformat(start_time.replace('Z', '+00:00'))\n",
        "                    actual_dt = start_dt + timedelta(hours=position-1)\n",
        "                    \n",
        "                    data.append({\n",
        "                        'datetime': actual_dt,\n",
        "                        'price': price\n",
        "                    })\n",
        "                except Exception as e:\n",
        "                    continue\n",
        "        \n",
        "        if data and len(data) > 0:\n",
        "            df = pd.DataFrame(data)\n",
        "            df = df.sort_values('datetime').reset_index(drop=True)\n",
        "            return df\n",
        "        else:\n",
        "            return None\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing price data: {e}\")\n",
        "        return None\n",
        "\n",
        "def generate_synthetic_data(n_samples=8760, start_date='2023-01-01'):\n",
        "    \"\"\"Generate synthetic electricity price data.\"\"\"\n",
        "    print(\"Generating synthetic electricity price data...\")\n",
        "    \n",
        "    dates = pd.date_range(start=start_date, periods=n_samples, freq='h')\n",
        "    \n",
        "    # Base price with seasonal patterns\n",
        "    base_price = 50 + 20 * np.sin(2 * np.pi * np.arange(n_samples) / (24 * 365))  # Annual seasonality\n",
        "    base_price += 10 * np.sin(2 * np.pi * np.arange(n_samples) / 24)  # Daily seasonality\n",
        "    \n",
        "    # Add some realistic volatility\n",
        "    noise = np.random.normal(0, 15, n_samples)\n",
        "    prices = base_price + noise\n",
        "    \n",
        "    # Add some extreme spikes (realistic for electricity markets)\n",
        "    spike_indices = np.random.choice(n_samples, size=int(0.01 * n_samples), replace=False)\n",
        "    prices[spike_indices] *= np.random.uniform(2, 5, len(spike_indices))\n",
        "    \n",
        "    # Ensure prices are positive\n",
        "    prices = np.maximum(prices, 5)\n",
        "    \n",
        "    data = pd.DataFrame({\n",
        "        'datetime': dates,\n",
        "        'price': prices,\n",
        "        'hour': dates.hour,\n",
        "        'day_of_week': dates.dayofweek,\n",
        "        'month': dates.month,\n",
        "        'year': dates.year\n",
        "    })\n",
        "    \n",
        "    print(f\"Generated {len(data)} synthetic price records\")\n",
        "    return data\n",
        "\n",
        "# Get the data (real or synthetic)\n",
        "print(\"Trying to get real data...\")\n",
        "data = get_real_data()\n",
        "\n",
        "print(f\"\\nData ready!\")\n",
        "print(f\"Records: {len(data)}\")\n",
        "print(f\"Date range: {data['datetime'].min()} to {data['datetime'].max()}\")\n",
        "print(f\"Price range: €{data['price'].min():.2f} - €{data['price'].max():.2f}/MWh\")\n",
        "print(\"\\nSample data:\")\n",
        "print(data.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Data Preprocessing and Feature Engineering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preprocess data and engineer features\n",
        "preprocessor = DataPreprocessor()\n",
        "\n",
        "# Check data structure first\n",
        "print(\"Data Analysis:\")\n",
        "print(f\"Columns: {data.columns.tolist()}\")\n",
        "print(f\"Shape: {data.shape}\")\n",
        "print(f\"Date range: {data['datetime'].min()} to {data['datetime'].max()}\")\n",
        "print(f\"Price range: €{data['price'].min():.2f} - €{data['price'].max():.2f}/MWh\")\n",
        "\n",
        "# Set datetime as index\n",
        "if 'datetime' in data.columns:\n",
        "    data = data.set_index('datetime')\n",
        "    print(\"Set 'datetime' as index\")\n",
        "else:\n",
        "    print(\"'datetime' column not found. Available columns:\", data.columns.tolist())\n",
        "\n",
        "# Clean and preprocess data\n",
        "print(\"\\nCleaning data...\")\n",
        "clean_data = preprocessor.clean_price_data(data)\n",
        "print(f\"Cleaned data shape: {clean_data.shape}\")\n",
        "\n",
        "# Engineer features\n",
        "print(\"Engineering features...\")\n",
        "features_df = preprocessor.engineer_features(clean_data)\n",
        "print(f\"Features shape: {features_df.shape}\")\n",
        "print(f\"Feature columns: {features_df.columns.tolist()}\")\n",
        "\n",
        "# Handle missing values (important for ML models)\n",
        "print(\"\\nHandling missing values...\")\n",
        "print(f\"Missing values before: {features_df.isnull().sum().sum()}\")\n",
        "\n",
        "# Fill missing values with forward fill, then backward fill\n",
        "features_df = features_df.fillna(method='ffill').fillna(method='bfill')\n",
        "\n",
        "# If still missing values, fill with mean\n",
        "features_df = features_df.fillna(features_df.mean())\n",
        "\n",
        "print(f\"Missing values after: {features_df.isnull().sum().sum()}\")\n",
        "\n",
        "# Prepare training data\n",
        "print(\"\\nPreparing training data...\")\n",
        "X_train, X_test, y_train, y_test = preprocessor.prepare_training_data(\n",
        "    target_column='price',\n",
        "    test_size=0.2\n",
        ")\n",
        "\n",
        "print(f\"Training data: {X_train.shape}\")\n",
        "print(f\"Test data: {X_test.shape}\")\n",
        "print(f\"Training missing values: {X_train.isnull().sum().sum()}\")\n",
        "print(f\"Test missing values: {X_test.isnull().sum().sum()}\")\n",
        "\n",
        "# Display sample of processed data\n",
        "print(\"\\nSample processed data:\")\n",
        "print(features_df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model Training - Multiple Algorithms\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train multiple models for comparison\n",
        "print(\"Training models...\")\n",
        "\n",
        "# Handle infinity and extreme values\n",
        "print(\"Handling infinity and extreme values...\")\n",
        "print(f\"Infinity values in X_train: {np.isinf(X_train).sum().sum()}\")\n",
        "print(f\"Infinity values in X_test: {np.isinf(X_test).sum().sum()}\")\n",
        "\n",
        "# Replace infinity with NaN, then fill with median\n",
        "X_train = X_train.replace([np.inf, -np.inf], np.nan)\n",
        "X_test = X_test.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "# Fill NaN values with median (more robust than mean for extreme values)\n",
        "X_train = X_train.fillna(X_train.median())\n",
        "X_test = X_test.fillna(X_train.median())  # Use training median for test data\n",
        "\n",
        "print(f\"After cleaning - Infinity values in X_train: {np.isinf(X_train).sum().sum()}\")\n",
        "print(f\"After cleaning - Infinity values in X_test: {np.isinf(X_test).sum().sum()}\")\n",
        "\n",
        "# Additional NaN cleaning\n",
        "print(f\"NaN values in X_train after median fill: {X_train.isnull().sum().sum()}\")\n",
        "print(f\"NaN values in X_test after median fill: {X_test.isnull().sum().sum()}\")\n",
        "\n",
        "# Final cleanup - forward fill, then backward fill, then zero fill\n",
        "X_train = X_train.ffill().bfill().fillna(0)\n",
        "X_test = X_test.ffill().bfill().fillna(0)\n",
        "\n",
        "print(f\"Final NaN values in X_train: {X_train.isnull().sum().sum()}\")\n",
        "print(f\"Final NaN values in X_test: {X_test.isnull().sum().sum()}\")\n",
        "\n",
        "# Ensure no infinity values remain\n",
        "X_train = X_train.replace([np.inf, -np.inf], 0)\n",
        "X_test = X_test.replace([np.inf, -np.inf], 0)\n",
        "\n",
        "print(f\"Final infinity check - X_train: {np.isinf(X_train).sum().sum()}\")\n",
        "print(f\"Final infinity check - X_test: {np.isinf(X_test).sum().sum()}\")\n",
        "\n",
        "# Train baseline models\n",
        "print(\"\\nTraining baseline models...\")\n",
        "baseline_models = BaselineModels()\n",
        "baseline_models.train_all(X_train, y_train)\n",
        "baseline_predictions = baseline_models.predict_all(X_test)\n",
        "baseline_results = baseline_models.evaluate_all(y_test, baseline_predictions)\n",
        "\n",
        "print(\"Baseline models trained successfully!\")\n",
        "\n",
        "# Train ML models\n",
        "print(\"\\nTraining ML models...\")\n",
        "ml_models = MLModels()\n",
        "ml_models.train_all(X_train, y_train, tune_hyperparameters=False)\n",
        "ml_predictions = ml_models.predict_all(X_test)\n",
        "ml_results = ml_models.evaluate_all(y_test, ml_predictions)\n",
        "\n",
        "print(\"ML models trained successfully!\")\n",
        "\n",
        "# Combine all results\n",
        "all_predictions = {**baseline_predictions, **ml_predictions}\n",
        "all_results = {**baseline_results, **ml_results}\n",
        "\n",
        "print(f\"\\nAll models trained! Total models: {len(all_predictions)}\")\n",
        "print(\"Model names:\", list(all_predictions.keys()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Model Evaluation and Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comprehensive evaluation and visualization\n",
        "evaluator = EvaluationMetrics()\n",
        "\n",
        "# Calculate metrics for all models\n",
        "print(\"Calculating evaluation metrics...\")\n",
        "evaluation_results = {}\n",
        "for model_name, pred in all_predictions.items():\n",
        "    metrics = evaluator.calculate_all_metrics(y_test, pred, model_name)\n",
        "    evaluation_results[model_name] = metrics\n",
        "\n",
        "# Create comparison DataFrame\n",
        "comparison_df = evaluator.compare_models(evaluation_results)\n",
        "print(\"\\nModel Performance Comparison:\")\n",
        "print(comparison_df.round(4))\n",
        "\n",
        "# Create interactive visualization\n",
        "print(\"\\nCreating interactive visualization...\")\n",
        "fig = go.Figure()\n",
        "\n",
        "# Add actual values\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=list(range(len(y_test))), \n",
        "    y=y_test.values, \n",
        "    mode='lines', \n",
        "    name='Actual', \n",
        "    line=dict(width=2, color='black')\n",
        "))\n",
        "\n",
        "# Add predictions for each model\n",
        "colors = ['red', 'blue', 'green', 'orange', 'purple', 'brown', 'pink', 'gray']\n",
        "for i, (model_name, pred) in enumerate(all_predictions.items()):\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=list(range(len(y_test))), \n",
        "        y=pred, \n",
        "        mode='lines', \n",
        "        name=model_name,\n",
        "        line=dict(color=colors[i % len(colors)], width=1)\n",
        "    ))\n",
        "\n",
        "fig.update_layout(\n",
        "    title='Electricity Price Predictions vs Actual',\n",
        "    xaxis_title='Time Index',\n",
        "    yaxis_title='Price (€/MWh)',\n",
        "    width=1000,\n",
        "    height=600\n",
        ")\n",
        "\n",
        "fig.show()\n",
        "\n",
        "# Display best model\n",
        "best_model_name = comparison_df.index[0]\n",
        "best_rmse = comparison_df.loc[best_model_name, 'rmse']\n",
        "best_mae = comparison_df.loc[best_model_name, 'mae']\n",
        "\n",
        "print(f\"\\nBest Model: {best_model_name}\")\n",
        "print(f\"RMSE: {best_rmse:.2f} €/MWh\")\n",
        "print(f\"MAE: {best_mae:.2f} €/MWh\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Business Impact Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Business impact analysis\n",
        "print(\"Business Impact Analysis\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Get best model predictions\n",
        "best_model_name = comparison_df.index[0]\n",
        "best_pred = all_predictions[best_model_name]\n",
        "\n",
        "# Calculate business metrics\n",
        "total_cost_error = np.sum(np.abs(y_test - best_pred))\n",
        "avg_cost_error = total_cost_error / len(y_test)\n",
        "max_error = np.max(np.abs(y_test - best_pred))\n",
        "min_error = np.min(np.abs(y_test - best_pred))\n",
        "\n",
        "# Calculate percentage errors\n",
        "mape = np.mean(np.abs((y_test - best_pred) / y_test)) * 100\n",
        "rmse = np.sqrt(np.mean((y_test - best_pred) ** 2))\n",
        "\n",
        "print(f\"Best Model: {best_model_name}\")\n",
        "print(f\"RMSE: {rmse:.2f} €/MWh\")\n",
        "print(f\"MAE: {avg_cost_error:.2f} €/MWh\")\n",
        "print(f\"MAPE: {mape:.2f}%\")\n",
        "print(f\"Max Error: {max_error:.2f} €/MWh\")\n",
        "print(f\"Min Error: {min_error:.2f} €/MWh\")\n",
        "\n",
        "# Business scenarios\n",
        "print(f\"\\nBusiness Impact Scenarios:\")\n",
        "print(f\"Total cost error over test period: €{total_cost_error:.2f}\")\n",
        "print(f\"Average cost error per hour: €{avg_cost_error:.2f}\")\n",
        "print(f\"Daily cost error (24h): €{avg_cost_error * 24:.2f}\")\n",
        "print(f\"Monthly cost error (30d): €{avg_cost_error * 24 * 30:.2f}\")\n",
        "\n",
        "# Error distribution analysis\n",
        "errors = np.abs(y_test - best_pred)\n",
        "print(f\"\\nError Distribution:\")\n",
        "print(f\"50th percentile error: €{np.percentile(errors, 50):.2f}\")\n",
        "print(f\"75th percentile error: €{np.percentile(errors, 75):.2f}\")\n",
        "print(f\"90th percentile error: €{np.percentile(errors, 90):.2f}\")\n",
        "print(f\"95th percentile error: €{np.percentile(errors, 95):.2f}\")\n",
        "\n",
        "# Create error distribution plot\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Histogram(\n",
        "    x=errors,\n",
        "    nbinsx=50,\n",
        "    name='Error Distribution',\n",
        "    marker_color='lightblue'\n",
        "))\n",
        "\n",
        "fig.update_layout(\n",
        "    title='Prediction Error Distribution',\n",
        "    xaxis_title='Absolute Error (€/MWh)',\n",
        "    yaxis_title='Frequency',\n",
        "    width=800,\n",
        "    height=400\n",
        ")\n",
        "\n",
        "fig.show()\n",
        "\n",
        "print(f\"\\nAnalysis complete! The {best_model_name} model provides the best forecasting accuracy.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Next Steps and Recommendations\n",
        "\n",
        "### What You Can Do Next:\n",
        "\n",
        "1. **Get Your Own API Token**\n",
        "   - Register at https://transparency.entsoe.eu/\n",
        "   - Replace the token in the data collection cell\n",
        "   - Get real-time data for your country\n",
        "\n",
        "2. **Experiment with Models**\n",
        "   - Try different hyperparameters\n",
        "   - Add more features (weather, demand, etc.)\n",
        "   - Test ensemble methods\n",
        "\n",
        "3. **Improve Accuracy**\n",
        "   - Add external data sources\n",
        "   - Implement feature selection\n",
        "   - Try deep learning models\n",
        "\n",
        "4. **Deploy Your Model**\n",
        "   - Export trained models\n",
        "   - Create a web application\n",
        "   - Set up automated predictions\n",
        "\n",
        "5. **Business Applications**\n",
        "   - Trading strategies\n",
        "   - Risk management\n",
        "   - Cost optimization\n",
        "\n",
        "### Tips for Google Colab:\n",
        "\n",
        "- **Enable GPU**: Runtime > Change runtime type > GPU\n",
        "- **Save Progress**: Mount Google Drive to save results\n",
        "- **Session Management**: Colab sessions timeout after inactivity\n",
        "- **Memory Limits**: Large datasets may hit memory limits\n",
        "- **Install Once**: Run setup cell only once per session\n",
        "\n",
        "### Troubleshooting:\n",
        "\n",
        "- **Import Errors**: Make sure you're in the correct directory\n",
        "- **Memory Issues**: Reduce dataset size or use smaller models\n",
        "- **Timeout**: Save work frequently and restart if needed\n",
        "- **API Errors**: Check your ENTSO-E token is valid\n",
        "\n",
        "---\n",
        "\n",
        "## Congratulations!\n",
        "\n",
        "You've successfully built a complete electricity price forecasting system! This notebook demonstrates:\n",
        "\n",
        "- Real data collection from ENTSO-E API  \n",
        "- Multiple machine learning models  \n",
        "- Comprehensive evaluation metrics  \n",
        "- Interactive visualizations  \n",
        "- Business impact analysis  \n",
        "- Robust error handling  \n",
        "\n",
        "**Happy Forecasting!**\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
